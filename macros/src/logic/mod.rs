//! Ascent Datalog code generation
//!
//! This module orchestrates the generation of Ascent Datalog code for a theory.
//!
//! ## Structure
//!
//! - `relations` - Relation declarations (categories, equality, rewrites, projections)
//! - `categories` - Category exploration and term deconstruction rules
//! - `equations` - Equality/equation rules with congruence
//! - `rewrites/` - Base rewrite rules and pattern/RHS generation
//! - `congruence/` - Congruence rules for rewrites (collection, regular, binding)
//!
//! ## Generated Code Components
//!
//! 1. **Relations**: Declare all Ascent relations for terms, equality, and rewrites
//! 2. **Category Rules**: Explore term space via rewrites and deconstruct terms
//! 3. **Equation Rules**: Add reflexivity, congruence, and user-defined equalities
//! 4. **Rewrite Rules**: Base rewrites + congruence rules (propagate through constructors)

use crate::ast::{language::{LanguageDef, BuiltinOp, SemanticOperation}, grammar::GrammarItem};
use proc_macro2::{Ident, TokenStream};
use quote::{format_ident, quote};

mod categories;
mod equations;
mod relations;
mod writer;

pub mod congruence;
pub mod rewrites;
pub mod rules;

// Re-export key functions
pub use categories::generate_category_rules;
pub use equations::generate_equation_rules;
pub use relations::generate_relations;

// Re-export congruence function
pub use congruence::generate_all_explicit_congruences;

pub use rewrites::{generate_freshness_functions, generate_rewrite_clauses};

/// Main entry point: Generate complete Ascent source for a theory
pub fn generate_ascent_source(language: &LanguageDef) -> TokenStream {
    let theory_name = language.name.to_string().to_lowercase();
    let source_name = format_ident!("{}_source", theory_name);

    let relations = generate_relations(language);
    let category_rules = generate_category_rules(language);
    let equation_rules = generate_equation_rules(language);
    let rewrite_rules = generate_rewrite_rules(language);

    let result = quote! {
        ::ascent::ascent_source! {
            #source_name:

            #relations

            #category_rules

            #equation_rules

            #rewrite_rules
        }
    };

    // Format and write the generated Ascent source to file
    let formatted_source = format_ascent_source(
        &theory_name,
        &source_name,
        &relations,
        &category_rules,
        &equation_rules,
        &rewrite_rules,
    );

    // Write to file for inspection
    if let Err(e) = writer::write_ascent_file(&language.name.to_string(), &formatted_source) {
        eprintln!("Warning: Failed to write Ascent Datalog file: {}", e);
    }

    result
}

/// Format Ascent source for display and file output
fn format_ascent_source(
    theory_name: &str,
    source_name: &Ident,
    relations: &TokenStream,
    category_rules: &TokenStream,
    equation_rules: &TokenStream,
    rewrite_rules: &TokenStream,
) -> String {
    let mut output = String::new();

    output.push_str(&format!("// Generated Ascent Datalog for {} theory\n", theory_name));
    output.push_str("// This file is generated by the theory! macro and is for inspection only.\n");
    output.push_str("// Do not edit manually - changes will be overwritten.\n\n");

    output.push_str("ascent_source! {\n");
    output.push_str(&format!("    {}:\n\n", source_name));

    output.push_str("    // Relations\n");
    for line in relations.to_string().split(';') {
        output.push_str(&print_rule(line));
    }

    output.push_str("\n    // Category rules\n");
    for line in category_rules.to_string().split(';') {
        output.push_str(&print_rule(line));
    }

    output.push_str("\n    // Equation rules\n");
    for line in equation_rules.to_string().split(';') {
        output.push_str(&print_rule(line));
    }

    output.push_str("\n    // Rewrite rules\n");
    for line in rewrite_rules.to_string().split(';') {
        output.push_str(&print_rule(line));
    }

    output.push_str("}\n");

    output
}

/// Generate rewrite rules: base rewrites + explicit congruence rules
///
/// - **Base rewrites**: Rules without premises (S => T)
/// - **Explicit congruences**: Rules with premises (if S => T then LHS => RHS)
/// - **Semantic evaluation**: Rules for built-in operators (Add, Sub, etc.)
/// - **Beta reduction**: Rules for Apply variants (ApplyName(LamName(...), arg) => ...)
///
/// Note: Rewrite congruences are NOT auto-generated. Users explicitly control
/// where rewrites propagate by writing `if S => T then ...` rules.
pub fn generate_rewrite_rules(language: &LanguageDef) -> TokenStream {
    let mut rules = Vec::new();

    // Generate base rewrite clauses (no premise)
    let base_rewrite_clauses = generate_rewrite_clauses(language);
    rules.extend(base_rewrite_clauses);

    // Generate semantic evaluation rules (for operators with semantics)
    let semantic_rules = generate_semantic_rules(language);
    rules.extend(semantic_rules);

    // Generate explicit congruence rules (with premise: if S => T then ...)
    // These are user-declared rules that control where rewrites propagate
    let congruence_rules = generate_all_explicit_congruences(language);
    rules.extend(congruence_rules);
    
    // Generate beta reduction rules for Apply variants
    let beta_rules = generate_beta_reduction_rules(language);
    rules.extend(beta_rules);

    quote! {
        #(#rules)*
    }
}

/// Generate beta reduction rules for Apply variants
/// 
/// For each Apply{Domain} variant, generates:
/// - ApplyDomain(LamDomain(scope), arg) => body[binder := arg]
/// - MApplyDomain(MLamDomain(scope), args) => body[binders := args]
fn generate_beta_reduction_rules(language: &LanguageDef) -> Vec<TokenStream> {
    let mut rules = Vec::new();
    
    // For each category (codomain)
    for codomain_lang_type in &language.types {
        if codomain_lang_type.native_type.is_some() {
            continue;
        }
        
        let codomain = &codomain_lang_type.name;
        let codomain_lower = codomain.to_string().to_lowercase();
        let rw_relation = syn::Ident::new(&format!("rw_{}", codomain_lower), proc_macro2::Span::call_site());
        let cat_relation = syn::Ident::new(&codomain_lower, proc_macro2::Span::call_site());
        
        // For each domain type
        for domain_lang_type in &language.types {
            if domain_lang_type.native_type.is_some() {
                continue;
            }
            
            let domain = &domain_lang_type.name;
            let domain_lower = domain.to_string().to_lowercase();
            let subst_method = syn::Ident::new(&format!("substitute_{}", domain_lower), proc_macro2::Span::call_site());
            let multi_subst_method = syn::Ident::new(&format!("multi_substitute_{}", domain_lower), proc_macro2::Span::call_site());
            
            let apply_variant = syn::Ident::new(&format!("Apply{}", domain), proc_macro2::Span::call_site());
            let lam_variant = syn::Ident::new(&format!("Lam{}", domain), proc_macro2::Span::call_site());
            let mapply_variant = syn::Ident::new(&format!("MApply{}", domain), proc_macro2::Span::call_site());
            let mlam_variant = syn::Ident::new(&format!("MLam{}", domain), proc_macro2::Span::call_site());
            
            // Single-argument beta reduction:
            // ApplyDomain(LamDomain(scope), arg) => body[binder := arg]
            rules.push(quote! {
                #rw_relation(s.clone(), t) <--
                    #cat_relation(s),
                    if let #codomain::#apply_variant(ref lam_box, ref arg_box) = s,
                    if let #codomain::#lam_variant(ref scope) = **lam_box,
                    let t = {
                        let (binder, body) = scope.clone().unbind();
                        (*body).#subst_method(&binder.0, &**arg_box)
                    };
            });
            
            // Multi-argument beta reduction:
            // MApplyDomain(MLamDomain(scope), args) => body[binders := args]
            rules.push(quote! {
                #rw_relation(s.clone(), t) <--
                    #cat_relation(s),
                    if let #codomain::#mapply_variant(ref lam_box, ref args) = s,
                    if let #codomain::#mlam_variant(ref scope) = **lam_box,
                    let t = {
                        let (binders, body) = scope.clone().unbind();
                        let vars: Vec<_> = binders.iter().map(|b| &b.0).collect();
                        (*body).#multi_subst_method(&vars, args)
                    };
            });
        }
    }
    
    rules
}

/// Generate semantic evaluation rules for constructors with semantics
/// For example: Add (NumLit a) (NumLit b) => NumLit(a + b)
fn generate_semantic_rules(language: &LanguageDef) -> Vec<TokenStream> {

    let mut rules = Vec::new();

    for semantic in &language.semantics {
        let constructor_name = &semantic.constructor;

        // Extract the operator
        let op_token = match &semantic.operation {
            SemanticOperation::Builtin(builtin_op) => {
                match builtin_op {
                    BuiltinOp::Add => quote! { + },
                    BuiltinOp::Sub => quote! { - },
                    BuiltinOp::Mul => quote! { * },
                    BuiltinOp::Div => quote! { / },
                    BuiltinOp::Rem => quote! { % },
                    _ => continue, // Skip other operators
                }
            },
        };

        // Find the rule with this constructor
        if let Some(rule) = language.terms.iter().find(|r| r.label == *constructor_name) {
            // Check if this is a binary operator (should have exactly 2 non-terminal fields)
            let non_terminals: Vec<_> = rule
                .items
                .iter()
                .filter_map(|item| {
                    if let GrammarItem::NonTerminal(nt) = item {
                        Some(nt)
                    } else {
                        None
                    }
                })
                .collect();

            if non_terminals.len() == 2 {
                let category = &rule.category;
                let label = &rule.label;

                // Generate rule with proper variable extraction in the head
                let rw_rel = format_ident!("rw_{}", category.to_string().to_lowercase());
                let cat_rel = format_ident!("{}", category.to_string().to_lowercase());
                let num_lit = format_ident!("NumLit");

                // Pattern: rw_cat(s, t) with body that matches and extracts a, b
                rules.push(quote! {
                    #rw_rel(s, t) <--
                        #cat_rel(s),
                        if let #category::#label(left, right) = s,
                        if let #category::#num_lit(a) = left.as_ref(),
                        if let #category::#num_lit(b) = right.as_ref(),
                        let t = #category::#num_lit(a #op_token b);
                });
            }
        }
    }

    rules
}

pub fn split_commas_outside_parens(s: &str) -> Vec<&str> {
    let mut result = Vec::new();
    let mut depth = 0;
    let mut start = 0;

    for (i, ch) in s.char_indices() {
        match ch {
            '(' => depth += 1,
            ')' => depth -= 1,
            ',' if depth == 0 => {
                result.push(&s[start..i]);
                start = i + 1;
            },
            _ => {},
        }
    }

    // Add the last segment
    if start <= s.len() {
        result.push(&s[start..]);
    }

    result
}

/// Normalize whitespace in a string by replacing all consecutive whitespace
/// (including newlines) with a single space. This fixes formatting issues
/// from TokenStream::to_string() which can insert unwanted line breaks.
fn normalize_whitespace(s: &str) -> String {
    s.split_whitespace().collect::<Vec<_>>().join(" ")
}

pub fn print_rule(line: &str) -> String {
    if line.trim().is_empty() {
        return String::new();
    }

    // Normalize whitespace to fix TokenStream formatting issues
    let normalized = normalize_whitespace(line);

    let (head, body) = normalized
        .split_once("<- -")
        .unwrap_or((normalized.trim(), ""));
    let head_clauses = split_commas_outside_parens(head);
    let (head_last, head_rest) = head_clauses.split_last().unwrap_or((&"", &[]));
    let clauses = split_commas_outside_parens(body);
    let (last, rest) = clauses.split_last().unwrap_or((&"", &[]));
    if !body.trim().is_empty() {
        let mut result = String::new();
        for clause in head_rest {
            result.push_str(&format!("{},\n", clause.trim()));
        }
        result.push_str(&format!("{} <--\n", head_last.trim()));
        for clause in rest {
            result.push_str(&format!("    {},\n", clause.trim()));
        }
        result.push_str(&format!("    {};\n\n", last.trim()));
        result.to_string()
    } else {
        format!("{};\n\n", normalized.trim())
    }
}
