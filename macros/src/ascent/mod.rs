//! Ascent Datalog code generation
//!
//! This module orchestrates the generation of Ascent Datalog code for a theory.
//!
//! ## Structure
//!
//! - `relations` - Relation declarations (categories, equality, rewrites, projections)
//! - `categories` - Category exploration and term deconstruction rules
//! - `equations` - Equality/equation rules with congruence
//! - `rewrites/` - Base rewrite rules and pattern/RHS generation
//! - `congruence/` - Congruence rules for rewrites (collection, regular, binding)
//!
//! ## Generated Code Components
//!
//! 1. **Relations**: Declare all Ascent relations for terms, equality, and rewrites
//! 2. **Category Rules**: Explore term space via rewrites and deconstruct terms
//! 3. **Equation Rules**: Add reflexivity, congruence, and user-defined equalities
//! 4. **Rewrite Rules**: Base rewrites + congruence rules (propagate through constructors)

use crate::ast::{theory::{TheoryDef, BuiltinOp, SemanticOperation}, grammar::GrammarItem};
use proc_macro2::{Ident, TokenStream};
use crate::utils::print_rule;
use quote::{format_ident, quote};

mod categories;
mod equations;
mod relations;
mod writer;

pub mod congruence;
pub mod rewrites;
pub mod rules;

// Re-export key functions
pub use categories::generate_category_rules;
pub use equations::generate_equation_rules;
pub use relations::generate_relations;

// Re-export congruence function
pub use congruence::generate_all_explicit_congruences;

pub use rewrites::{generate_freshness_functions, generate_rewrite_clauses};

/// Main entry point: Generate complete Ascent source for a theory
pub fn generate_ascent_source(theory: &TheoryDef) -> TokenStream {
    let theory_name = theory.name.to_string().to_lowercase();
    let source_name = format_ident!("{}_source", theory_name);

    let relations = generate_relations(theory);
    let category_rules = generate_category_rules(theory);
    let equation_rules = generate_equation_rules(theory);
    let rewrite_rules = generate_rewrite_rules(theory);

    let result = quote! {
        ::ascent::ascent_source! {
            #source_name:

            #relations

            #category_rules

            #equation_rules

            #rewrite_rules
        }
    };

    // Format and write the generated Ascent source to file
    let formatted_source = format_ascent_source(
        &theory_name,
        &source_name,
        &relations,
        &category_rules,
        &equation_rules,
        &rewrite_rules,
    );

    // Write to file for inspection
    if let Err(e) = writer::write_ascent_file(&theory.name.to_string(), &formatted_source) {
        eprintln!("Warning: Failed to write Ascent Datalog file: {}", e);
    }

    result
}

/// Format Ascent source for display and file output
fn format_ascent_source(
    theory_name: &str,
    source_name: &Ident,
    relations: &TokenStream,
    category_rules: &TokenStream,
    equation_rules: &TokenStream,
    rewrite_rules: &TokenStream,
) -> String {
    let mut output = String::new();

    output.push_str(&format!("// Generated Ascent Datalog for {} theory\n", theory_name));
    output.push_str("// This file is generated by the theory! macro and is for inspection only.\n");
    output.push_str("// Do not edit manually - changes will be overwritten.\n\n");

    output.push_str("ascent_source! {\n");
    output.push_str(&format!("    {}:\n\n", source_name));

    output.push_str("    // Relations\n");
    for line in relations.to_string().split(';') {
        output.push_str(&print_rule(line));
    }

    output.push_str("\n    // Category rules\n");
    for line in category_rules.to_string().split(';') {
        output.push_str(&print_rule(line));
    }

    output.push_str("\n    // Equation rules\n");
    for line in equation_rules.to_string().split(';') {
        output.push_str(&print_rule(line));
    }

    output.push_str("\n    // Rewrite rules\n");
    for line in rewrite_rules.to_string().split(';') {
        output.push_str(&print_rule(line));
    }

    output.push_str("}\n");

    output
}

/// Generate rewrite rules: base rewrites + explicit congruence rules
///
/// - **Base rewrites**: Rules without premises (S => T)
/// - **Explicit congruences**: Rules with premises (if S => T then LHS => RHS)
/// - **Semantic evaluation**: Rules for built-in operators (Add, Sub, etc.)
///
/// Note: Rewrite congruences are NOT auto-generated. Users explicitly control
/// where rewrites propagate by writing `if S => T then ...` rules.
pub fn generate_rewrite_rules(theory: &TheoryDef) -> TokenStream {
    let mut rules = Vec::new();

    // Generate base rewrite clauses (no premise)
    let base_rewrite_clauses = generate_rewrite_clauses(theory);
    rules.extend(base_rewrite_clauses);

    // Generate semantic evaluation rules (for operators with semantics)
    let semantic_rules = generate_semantic_rules(theory);
    rules.extend(semantic_rules);

    // Generate explicit congruence rules (with premise: if S => T then ...)
    // These are user-declared rules that control where rewrites propagate
    let congruence_rules = generate_all_explicit_congruences(theory);
    rules.extend(congruence_rules);

    quote! {
        #(#rules)*
    }
}

/// Generate semantic evaluation rules for constructors with semantics
/// For example: Add (NumLit a) (NumLit b) => NumLit(a + b)
fn generate_semantic_rules(theory: &TheoryDef) -> Vec<TokenStream> {

    let mut rules = Vec::new();

    for semantic in &theory.semantics {
        let constructor_name = &semantic.constructor;

        // Extract the operator
        let op_token = match &semantic.operation {
            SemanticOperation::Builtin(builtin_op) => {
                match builtin_op {
                    BuiltinOp::Add => quote! { + },
                    BuiltinOp::Sub => quote! { - },
                    BuiltinOp::Mul => quote! { * },
                    BuiltinOp::Div => quote! { / },
                    BuiltinOp::Rem => quote! { % },
                    _ => continue, // Skip other operators
                }
            },
        };

        // Find the rule with this constructor
        if let Some(rule) = theory.terms.iter().find(|r| r.label == *constructor_name) {
            // Check if this is a binary operator (should have exactly 2 non-terminal fields)
            let non_terminals: Vec<_> = rule
                .items
                .iter()
                .filter_map(|item| {
                    if let GrammarItem::NonTerminal(nt) = item {
                        Some(nt)
                    } else {
                        None
                    }
                })
                .collect();

            if non_terminals.len() == 2 {
                let category = &rule.category;
                let label = &rule.label;

                // Generate rule with proper variable extraction in the head
                let rw_rel = format_ident!("rw_{}", category.to_string().to_lowercase());
                let cat_rel = format_ident!("{}", category.to_string().to_lowercase());
                let num_lit = format_ident!("NumLit");

                // Pattern: rw_cat(s, t) with body that matches and extracts a, b
                rules.push(quote! {
                    #rw_rel(s, t) <--
                        #cat_rel(s),
                        if let #category::#label(left, right) = s,
                        if let #category::#num_lit(a) = left.as_ref(),
                        if let #category::#num_lit(b) = right.as_ref(),
                        let t = #category::#num_lit(a #op_token b);
                });
            }
        }
    }

    rules
}
